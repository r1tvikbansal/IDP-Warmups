{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BimALP1lebCx"
   },
   "source": [
    "# Neural Networks Code: Digit Recognition\n",
    "\n",
    "In this notebook, we will show how to train a model to classify handwritten digits (0-9).\n",
    "\n",
    "First we start by importing some libraries.\n",
    "\n",
    "This page is highly related to our [Online Book](https://cse163.github.io/book/module-8-images/lesson-24-reading-machine-learning-and-images/neural-networks-code/Neural_Networks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MhqvKP8tdJ3Y"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhIIHlMn96Az"
   },
   "source": [
    "We need to load in the MNIST dataset of hand-written digits with their labels. Each example is a 28x28 grayscale image and its label is a number from 0 to 9. As we mentioned, it's common to \"unroll\" images for machine learning, so the return value for the training set will be a `numpy.array` with shape `(n, 784)` where `n` is the number of examples in the dataset. \n",
    "\n",
    "Many machine learning algorithms require the inputs be scaled to appropriate values, so we first change the range of the pixel values to be between 0 and 1. \n",
    "\n",
    "In Mathematics, it is a common convention to use a capital letter to represent a matrix. While this is not necessarily a convention in Python, you'll find that this mathematic's convention bleeds over into code from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2el6fDfotikN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "69995    2\n",
       "69996    3\n",
       "69997    4\n",
       "69998    5\n",
       "69999    6\n",
       "Name: class, Length: 70000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the data takes a few seconds\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, parser='auto', return_X_y=True)\n",
    "X = X / 255.\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Q1: What is fetch_openml? What is in X and y? What are their shapes?__\n",
    "> A1: It is a function that can fetch datasets by openml. X (shape: (70000, 784)) and y (shape: (70000,)) are tables. X has each image as an index with each pixel as a column and y has each image with its expected number shown in the image.\n",
    "\n",
    "* __Q2: What does the code do `X = X / 255`?__\n",
    "> A2: Machine Learning algorithms perfer input to be in the range of 0 and 1, so assigning by dividing by 255 we are essentially assigning a brightness value to each pixel rather than it's pixel value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cz00ct5-ISj"
   },
   "source": [
    "Then, instead of using `train_test_split` like we would do in most situations, we separate the train data as the first 60,000 rows and the test as the remaining rows. This is generally not a good idea in practice, but this dataset is provided by the author with those rows specifically to be used as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xeZsEwztlL3",
    "outputId": "4fd68b66-597b-45bb-b99d-9e89242d8b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "print(X_train.shape)\n",
    "img2 = np.array(X.loc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgY9206V-WTZ"
   },
   "source": [
    "This code cell above confirms the shape of the array we described earlier. We can use `reshape` to plot what the image looks like! The X is a DataFrame. We grab the 2nd element and convert to a Numpy array so that we can reshape and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "OC5XAZrxtvkX",
    "outputId": "b8b577b0-6fc6-4bd1-8cf6-cfd5382ca78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img2.reshape((28, 28)), cmap=plt.cm.gray)\n",
    "img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIlSiDvD_Nkh"
   },
   "source": [
    "We then go ahead to import and create a neural network using `sklearn`. Another name for a neural network is a \"multi-layer perceptron\", which explains the abbreviation `MLP`.\n",
    "\n",
    "The most important parameter to this function is the `hidden_layer_sizes` which specifies the number of hidden layers and the number of nodes that appear at each layer respectively. The remaining parameters are not as important and are there to keep the details of the output manageable. Confusingly in this paragraph, we refer to these as `parameters` since they are Python values you are passing. In reality they are technically the `hyperparameters` of the model since we are using them to specify what type of model we want! We provide `hyperparameter` values before the model learns. These `hyperparameters` define the model and how it will learn.\n",
    "\n",
    "By passing in `hidden_layer_sizes=(50,)` we are creating a neural network with one hidden layer, and that hidden layer has 50 nodes. The number of input and output neurons is determined by `sklearn` using the data you provide. So in this context, the network will have 784 input neurons, one layer of 50 neurons, and 10 output neurons (one for each digit).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5g_Ln6PK2ztE",
    "outputId": "556e4d0c-d268-4012-b69a-87938ed4afeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, random_state=1, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, random_state=1, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, random_state=1, verbose=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), \n",
    "                    max_iter=20, verbose=10, random_state=1)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Q3: What are the hyperparameters in the above code cell?__\n",
    "> A3: The hyperparameters are those specified in the MLPClassifier class which include hidden_layer_sizes, max_iter, verbose, and random_state.\n",
    "\n",
    "* __Q4: Use [MLPClassifier Documentation](.https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) to discover the default 'squashing' function__\n",
    "> A4: The squashing function is also called the activation function. The default used is relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma40M_UE_oDO"
   },
   "source": [
    "After we've created a model, we train the model on the `Training Set`. Then, we look at the training and test accuracy scores. Some things to notice:\n",
    "* While runnning `fit`, it prints out lines starting with `Iteration`. These lines inform us about the learning process which is done iteratively. With each iteration, the model gets smarter. With each iteration, the network model updates its weights based on the mis-classification (errors). The `loss` value is a measurement of how much error there is (but slightly different than accuracy).\n",
    "* With this architecture, we get really high training and test accuracy!\n",
    "\n",
    "*Note: You can ignore the convergence warning.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hBpR22o3SuZ",
    "outputId": "2880069b-2568-42f2-fc26-7193c0c6c363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.52090613\n",
      "Iteration 2, loss = 0.25006049\n",
      "Iteration 3, loss = 0.19728192\n",
      "Iteration 4, loss = 0.16435969\n",
      "Iteration 5, loss = 0.14179291\n",
      "Iteration 6, loss = 0.12474275\n",
      "Iteration 7, loss = 0.11050647\n",
      "Iteration 8, loss = 0.09964098\n",
      "Iteration 9, loss = 0.09138456\n",
      "Iteration 10, loss = 0.08368557\n",
      "Iteration 11, loss = 0.07653627\n",
      "Iteration 12, loss = 0.07102342\n",
      "Iteration 13, loss = 0.06611803\n",
      "Iteration 14, loss = 0.06165941\n",
      "Iteration 15, loss = 0.05796496\n",
      "Iteration 16, loss = 0.05423640\n",
      "Iteration 17, loss = 0.05091589\n",
      "Iteration 18, loss = 0.04768671\n",
      "Iteration 19, loss = 0.04379011\n",
      "Iteration 20, loss = 0.04129559\n",
      "Training score 0.9899\n",
      "Testing score 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "print('Training score', mlp.score(X_train, y_train))\n",
    "print('Testing score', mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Q5: What happens when you update the hyperparameter `max_iter` to some other value? Explain.__\n",
    "> A5: The number of iterations the model takes to train itself changes with the max_iter parameter. Increasing it from 10 to 20 brints the testing accuracy of the model from 0.968 to 0.9707. The more max interations we set, the more the accuracy I expect to see due to it eventually overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4pjff5NAWK0"
   },
   "source": [
    "These networks are very sensitive to the hyper-parameters we use (parameters that specify the algorithm or model we are using). If you go ahead and add more layers and shorten the number of nodes at each layer, you get a pretty different accuracy! In the following example, we change the architecture of the network to have 5 hidden layers of 10 nodes each.\n",
    "\n",
    "This is one example of the complexities of neural networks! It's hard to predict how changing the architecture will affect the performance of the model. You can see in [this tool](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.81962&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) how there are tons of knobs to tune for a neural network and it's very tough to predict how the output will be affected by those settings. This leads us to our next point of trying to find the best setting of these hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq5mX4ba3Ysm",
    "outputId": "2c7017cb-29c4-43b6-c793-08c0ae93fce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.45255343\n",
      "Iteration 2, loss = 0.57299610\n",
      "Iteration 3, loss = 0.38572560\n",
      "Iteration 4, loss = 0.32854750\n",
      "Iteration 5, loss = 0.30268236\n",
      "Iteration 6, loss = 0.28441232\n",
      "Iteration 7, loss = 0.27175338\n",
      "Iteration 8, loss = 0.26216631\n",
      "Iteration 9, loss = 0.25362123\n",
      "Iteration 10, loss = 0.24813976\n",
      "Training score 0.9289166666666666\n",
      "Testing score 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlpbest = MLPClassifier(hidden_layer_sizes=(10, 10, 10, 10, 10), \n",
    "                    max_iter=10, verbose=10, random_state=1)\n",
    "mlpbest.fit(X_train, y_train)\n",
    "print('Training score', mlpbest.score(X_train, y_train))\n",
    "print('Testing score', mlpbest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Q6: What does `hidden_layers_sizes=(10, 10, 10, 10, 10)` mean?__\n",
    "> A6: It means that there will be 5 hidden layers with 10 nodes each and this drastically changes the structure of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFIbnu6iMwG9"
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "Since there is no good way of telling \"what the best settings are\", the only thing really left is to try them all and see which one is best.\n",
    "\n",
    "For this example, we will try a few different network architectures as well as modifying a new parameter called the \"learning rate\"; this parameter essentially controls how much we update the weights by on each iteration.\n",
    "\n",
    "The nested loop below trying every possible setting is a very common piece of code for machine learning where we have to try all combinations of the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCN6EOhFMxXP",
    "outputId": "d866ff97-7506-4289-d8fe-587cd5a7f11c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.001, Size (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.935850\n",
      "    Test set score: 0.932600\n",
      "Learning Rate 0.001, Size (50,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.979383\n",
      "    Test set score: 0.968000\n",
      "Learning Rate 0.001, Size (10, 10, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.928017\n",
      "    Test set score: 0.921700\n",
      "Learning Rate 0.01, Size (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.922650\n",
      "    Test set score: 0.915000\n",
      "Learning Rate 0.01, Size (50,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.980800\n",
      "    Test set score: 0.965900\n",
      "Learning Rate 0.01, Size (10, 10, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.918150\n",
      "    Test set score: 0.909000\n",
      "Learning Rate 0.5, Size (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.102183\n",
      "    Test set score: 0.101000\n",
      "Learning Rate 0.5, Size (50,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training set score: 0.102183\n",
      "    Test set score: 0.101000\n",
      "Learning Rate 0.5, Size (10, 10, 10, 10)\n",
      "    Training set score: 0.112367\n",
      "    Test set score: 0.113500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.5]\n",
    "sizes = [(10,), (50,), (10, 10, 10, 10),]\n",
    "for learning_rate in learning_rates:\n",
    "    for size in sizes:\n",
    "        print(f'Learning Rate {learning_rate}, Size {size}')\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=size, max_iter=10,\n",
    "                            random_state=1, learning_rate_init=learning_rate)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        print(\"    Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "        print(\"    Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R8OGBMGBer2"
   },
   "source": [
    "How would we choose which hyper-parameters to use?\n",
    "\n",
    "*   Should we use the ones that maximize the training accuracy? Not necessarily since this might just select the most complicated model that is most likely to overfit to the data.\n",
    "*   Should we use the ones that maximize the test accuracy? This is a better idea since we we won't necessarily pick a model that overfit to the training set. However, this is not a good idea since it ruins the point of a test set! Why did we want the test set? We wanted a test set to let use give a good estimate of how our model will do in the future. If we picked a model that maximized the test-accuracy, this accuracy is no longer a good estimate of how it will do on future data since we chose the model that did best on that specific dataset.\n",
    "\n",
    "So to make this work, we generally split the training set into another set called the \"validation\" or \"dev\" set that we use to pick the hyper-parameter settings. Then we can leave the test set untouched until the very end of our project. At that point, we can test our final model we selected on that test set and get an accurate estimate of its performance in the future!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Q7: What hyperparameters were best?__\n",
    "> A7: The best hyperparameters were Learning Rate 0.01, Size (50,) and Learning Rate 0.001, Size (10, 10, 10, 10)\n",
    "\n",
    "* __Q8: Explain how having an extra, reserved dataset (called 'validation' or 'dev') is used and why? Does is seem similar to the Veritasium video, \"Is most published research wrong?\" How?__\n",
    "> A8: Having the extra reserved dataset allows us to set the hyperparameter settings and leave the test set untouched for the future when we want to get an accurate estimate of its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "Now that we have a better understanding of neural networks, we will briefly give you an idea of how that \"convolutional neural network\" (or CNN) we talked about in the last lesson works. A CNN is like any other neural network, but some of the layers use a special mechanism for a convolution. They treat the network weights for that layer as the the values inside the kernel, and then convolve those weights across the image to compute values.\n",
    "\n",
    "Generally, these convolutional layers happen earlier in the network since their job is to compute low-level features in the data (e.g., \"is there an edge here\"). The trick is that these convolutional layers learn their weights just like any other layer, so the network can essentially learn kernels that work best for its task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing Activity\n",
    "## Part 1\n",
    "Load the image named 'mynum3.png' found in the same folder as this notebook.\n",
    "\n",
    "  \n",
    "```python\n",
    "three = imageio.imread('mynum3.png')\n",
    "# adjust it and plot it\n",
    "plt.imshow(three, cmap=plt.cm.gray)\n",
    "```\n",
    "## Part 2\n",
    "Shape and convert the values so that it is a 1D array of length 784 and the values are between 0.0 and 1.0. In this case, the values will be either 0 or 1. Then, use one of the models trained above to make a prediction on this image. The call to `predict` takes an array of `examples` to predict. So, you'll need to pass in something of shape (1, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1115575\\.conda\\envs\\IDP3\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXNUlEQVR4nO3df6iW9f348dep7M7a8Qbxx33O1MMhjI0MIWuZlEXQIWGStUE/YNg/QZsKYjHWYuj2h0eC/Mu1WAxZrFZ/LFswWZyhHhvOIWIkLsLI5hl6OCTjvk3nEfP9/cNPh+9RM3+c4+v8eDzgDZ3rvs653+fq0qfXua/7fZpKKSUAIME12RMAYPwSIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEhzXfYEznb69Ok4dOhQNDc3R1NTU/Z0ALhEpZQ4evRotLa2xjXXXPhaZ8RF6NChQzFz5szsaQBwhXp6emLGjBkX3GfE/Tiuubk5ewoADIGL+ft82CL08ssvR3t7e9xwww0xb968eP/99y/q8/wIDmBsuJi/z4clQm+99VasXLkyXnjhhdizZ0/ce++9sWjRojh48OBwPB0Ao1TTcKyifdddd8Xtt98ev/nNbwa2ffe7340lS5ZEZ2fnBT+30WhEtVod6ikBcJXV6/WYNGnSBfcZ8iuhkydPxu7du6Ojo2PQ9o6OjtixY8c5+/f390ej0Rg0ABgfhjxCn3/+eXz55Zcxffr0QdunT58evb295+zf2dkZ1Wp1YLgzDmD8GLYbE85+QaqUct4XqZ5//vmo1+sDo6enZ7imBMAIM+TvE5oyZUpce+2151z19PX1nXN1FBFRqVSiUqkM9TQAGAWG/Ero+uuvj3nz5kVXV9eg7V1dXbFgwYKhfjoARrFhWTFh1apV8aMf/SjuuOOOuPvuu+O3v/1tHDx4MJ555pnheDoARqlhidBjjz0WR44ciV/96ldx+PDhmDNnTmzevDna2tqG4+kAGKWG5X1CV8L7hADGhpT3CQHAxRIhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkOa67AnASFJKyZ7CiNDU1JQ9BcYJV0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQWMGXEs6jo1Xe1jrmFUnElBEAaEQIgzZBHaM2aNdHU1DRo1Gq1oX4aAMaAYXlN6NZbb42//e1vAx9fe+21w/E0AIxywxKh6667ztUPAN9oWF4T2r9/f7S2tkZ7e3s8/vjj8emnn37tvv39/dFoNAYNAMaHIY/QXXfdFa+99lq899578eqrr0Zvb28sWLAgjhw5ct79Ozs7o1qtDoyZM2cO9ZQAGKGayjC/IeDYsWNx8803x09/+tNYtWrVOY/39/dHf3//wMeNRkOIGMT7hMYu7xMa2+r1ekyaNOmC+wz7m1VvuummuO2222L//v3nfbxSqUSlUhnuaQAwAg37+4T6+/vjo48+ipaWluF+KgBGmSGP0HPPPRfd3d1x4MCB+Oc//xk//OEPo9FoxNKlS4f6qQAY5Yb8x3H/+c9/4oknnojPP/88pk6dGvPnz4+dO3dGW1vbUD8VAKPcsN+YcKkajUZUq9XsaTBMRtjpNiTG4ovrFjBlKFzMjQnWjgMgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBn2X2rH2DWSFyO1MCaMDq6EAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANFbRZkSvhh1hRWwYy1wJAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSWMCUq8pipMD/z5UQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNBUyxqOgYVkrJngJckCshANKIEABpLjlC27dvj8WLF0dra2s0NTXFO++8M+jxUkqsWbMmWltbY+LEiXH//ffHvn37hmq+AIwhlxyhY8eOxdy5c2PDhg3nffzFF1+M9evXx4YNG2LXrl1Rq9XiwQcfjKNHj17xZAEYY8oViIiyadOmgY9Pnz5darVaWbdu3cC2EydOlGq1Wl555ZWL+pr1er1EhGEYQzBGuuzjYwzvqNfr33gODOlrQgcOHIje3t7o6OgY2FapVOK+++6LHTt2nPdz+vv7o9FoDBoAjA9DGqHe3t6IiJg+ffqg7dOnTx947GydnZ1RrVYHxsyZM4dySgCMYMNyd9zZ7zsppXzte1Gef/75qNfrA6Onp2c4pgTACDSkb1at1WoRceaKqKWlZWB7X1/fOVdHX6lUKlGpVIZyGgCMEkN6JdTe3h61Wi26uroGtp08eTK6u7tjwYIFQ/lUAIwBl3wl9MUXX8Qnn3wy8PGBAwfigw8+iMmTJ8esWbNi5cqVsXbt2pg9e3bMnj071q5dGzfeeGM8+eSTQzpxAMaAS72lcuvWree9FW/p0qWllDO3aa9evbrUarVSqVTKwoULy969ey/667tF2zCGbox02cfHGN5xMbdoN/3fiTBiNBqNqFar2dOAYTXC/tgNCQvhcrZ6vR6TJk264D7WjgMgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANIM6W9WhZFiLK5SfTVZEZurxZUQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNBUwZ8SxGevksRMpI50oIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZDGAqaMeGNxEc6rtSjr5T7PWDzmjEyuhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaSxgCgkuZ4HQq7XoKVxNroQASCNCAKS55Aht3749Fi9eHK2trdHU1BTvvPPOoMefeuqpaGpqGjTmz58/VPMFYAy55AgdO3Ys5s6dGxs2bPjafR566KE4fPjwwNi8efMVTRKAsemSb0xYtGhRLFq06IL7VCqVqNVqlz0pAMaHYXlNaNu2bTFt2rS45ZZb4umnn46+vr6v3be/vz8ajcagAcD4MOQRWrRoUbz++uuxZcuWeOmll2LXrl3xwAMPRH9//3n37+zsjGq1OjBmzpw51FMCYIRqKlfw5oOmpqbYtGlTLFmy5Gv3OXz4cLS1tcWbb74Zjz766DmP9/f3DwpUo9EQIjiPq/k+oct5HxOcrV6vx6RJky64z7C/WbWlpSXa2tpi//795328UqlEpVIZ7mkAMAIN+/uEjhw5Ej09PdHS0jLcTwXAKHPJV0JffPFFfPLJJwMfHzhwID744IOYPHlyTJ48OdasWRM/+MEPoqWlJT777LP4+c9/HlOmTIlHHnlkSCcOwBhQLtHWrVtLRJwzli5dWo4fP146OjrK1KlTy4QJE8qsWbPK0qVLy8GDBy/669fr9fN+fcMY7+Nqyv5ejbEx6vX6N55rV3RjwnBoNBpRrVazpwEjztX8o+rGBIbCxdyYYO04ANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABprsueAKNXKeWSP6epqWkYZjL6XM6xg7HIlRAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0FTLmqi2lauPPqsmAsI50rIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGguYctmLXFqMFLhSroQASCNCAKS5pAh1dnbGnXfeGc3NzTFt2rRYsmRJfPzxx4P2KaXEmjVrorW1NSZOnBj3339/7Nu3b0gnDcDYcEkR6u7ujmXLlsXOnTujq6srTp06FR0dHXHs2LGBfV588cVYv359bNiwIXbt2hW1Wi0efPDBOHr06JBPHoBRrlyBvr6+EhGlu7u7lFLK6dOnS61WK+vWrRvY58SJE6VarZZXXnnlor5mvV4vEWGMgsHIl32OGON71Ov1bzxHr+g1oXq9HhERkydPjoiIAwcORG9vb3R0dAzsU6lU4r777osdO3ac92v09/dHo9EYNAAYHy47QqWUWLVqVdxzzz0xZ86ciIjo7e2NiIjp06cP2nf69OkDj52ts7MzqtXqwJg5c+blTgmAUeayI7R8+fL48MMP449//OM5j539vpNSyte+F+X555+Per0+MHp6ei53SgCMMpf1ZtUVK1bEu+++G9u3b48ZM2YMbK/VahFx5oqopaVlYHtfX985V0dfqVQqUalULmcaAIxyl3QlVEqJ5cuXx9tvvx1btmyJ9vb2QY+3t7dHrVaLrq6ugW0nT56M7u7uWLBgwdDMGIAx45KuhJYtWxZvvPFG/PnPf47m5uaB13mq1WpMnDgxmpqaYuXKlbF27dqYPXt2zJ49O9auXRs33nhjPPnkk8PyDQAwig3F7Z4bN24c2Of06dNl9erVpVarlUqlUhYuXFj27t170c/hFu3RMxj5ss8RY3yPi7lFu+n/TtQRo9FoRLVazZ4GAFeoXq/HpEmTLriPteMASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgzSVFqLOzM+68885obm6OadOmxZIlS+Ljjz8etM9TTz0VTU1Ng8b8+fOHdNIAjA2XFKHu7u5YtmxZ7Ny5M7q6uuLUqVPR0dERx44dG7TfQw89FIcPHx4YmzdvHtJJAzA2XHcpO//1r38d9PHGjRtj2rRpsXv37li4cOHA9kqlErVabWhmCMCYdUWvCdXr9YiImDx58qDt27Zti2nTpsUtt9wSTz/9dPT19X3t1+jv749GozFoADA+NJVSyuV8YiklHn744fjvf/8b77///sD2t956K771rW9FW1tbHDhwIH7xi1/EqVOnYvfu3VGpVM75OmvWrIlf/vKXl/8dADAi1ev1mDRp0oV3KpfpJz/5SWlrays9PT0X3O/QoUNlwoQJ5U9/+tN5Hz9x4kSp1+sDo6enp0SEYRiGMcpHvV7/xpZc0mtCX1mxYkW8++67sX379pgxY8YF921paYm2trbYv3//eR+vVCrnvUICYOy7pAiVUmLFihWxadOm2LZtW7S3t3/j5xw5ciR6enqipaXlsicJwNh0STcmLFu2LP7whz/EG2+8Ec3NzdHb2xu9vb3xv//9LyIivvjii3juuefiH//4R3z22Wexbdu2WLx4cUyZMiUeeeSRYfkGABjFLuV1oPian/tt3LixlFLK8ePHS0dHR5k6dWqZMGFCmTVrVlm6dGk5ePDgRT9HvV5P/zmmYRiGceXjYl4Tuuy744ZLo9GIarWaPQ0ArtDF3B1n7TgA0ogQAGlECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiCNCAGQRoQASCNCAKQRIQDSiBAAaUQIgDQiBEAaEQIgjQgBkEaEAEgjQgCkESEA0oy4CJVSsqcAwBC4mL/PR1yEjh49mj0FAIbAxfx93lRG2KXH6dOn49ChQ9Hc3BxNTU2DHms0GjFz5szo6emJSZMmJc0wn+NwhuNwhuNwhuNwxkg4DqWUOHr0aLS2tsY111z4Wue6qzSni3bNNdfEjBkzLrjPpEmTxvVJ9hXH4QzH4QzH4QzH4Yzs41CtVi9qvxH34zgAxg8RAiDNqIpQpVKJ1atXR6VSyZ5KKsfhDMfhDMfhDMfhjNF2HEbcjQkAjB+j6koIgLFFhABII0IApBEhANKMqgi9/PLL0d7eHjfccEPMmzcv3n///ewpXVVr1qyJpqamQaNWq2VPa9ht3749Fi9eHK2trdHU1BTvvPPOoMdLKbFmzZpobW2NiRMnxv333x/79u3Lmeww+qbj8NRTT51zfsyfPz9nssOks7Mz7rzzzmhubo5p06bFkiVL4uOPPx60z3g4Hy7mOIyW82HUROitt96KlStXxgsvvBB79uyJe++9NxYtWhQHDx7MntpVdeutt8bhw4cHxt69e7OnNOyOHTsWc+fOjQ0bNpz38RdffDHWr18fGzZsiF27dkWtVosHH3xwzK1D+E3HISLioYceGnR+bN68+SrOcPh1d3fHsmXLYufOndHV1RWnTp2Kjo6OOHbs2MA+4+F8uJjjEDFKzocySnzve98rzzzzzKBt3/nOd8rPfvazpBldfatXry5z587NnkaqiCibNm0a+Pj06dOlVquVdevWDWw7ceJEqVar5ZVXXkmY4dVx9nEopZSlS5eWhx9+OGU+Wfr6+kpElO7u7lLK+D0fzj4OpYye82FUXAmdPHkydu/eHR0dHYO2d3R0xI4dO5JmlWP//v3R2toa7e3t8fjjj8enn36aPaVUBw4ciN7e3kHnRqVSifvuu2/cnRsREdu2bYtp06bFLbfcEk8//XT09fVlT2lY1ev1iIiYPHlyRIzf8+Hs4/CV0XA+jIoIff755/Hll1/G9OnTB22fPn169Pb2Js3q6rvrrrvitddei/feey9effXV6O3tjQULFsSRI0eyp5bmq///4/3ciIhYtGhRvP7667Fly5Z46aWXYteuXfHAAw9Ef39/9tSGRSklVq1aFffcc0/MmTMnIsbn+XC+4xAxes6HEbeK9oWc/asdSinnbBvLFi1aNPDft912W9x9991x8803x+9///tYtWpV4szyjfdzIyLiscceG/jvOXPmxB133BFtbW3xl7/8JR599NHEmQ2P5cuXx4cffhh///vfz3lsPJ0PX3ccRsv5MCquhKZMmRLXXnvtOf+S6evrO+dfPOPJTTfdFLfddlvs378/eyppvro70LlxrpaWlmhraxuT58eKFSvi3Xffja1btw761S/j7Xz4uuNwPiP1fBgVEbr++utj3rx50dXVNWh7V1dXLFiwIGlW+fr7++Ojjz6KlpaW7KmkaW9vj1qtNujcOHnyZHR3d4/rcyMi4siRI9HT0zOmzo9SSixfvjzefvvt2LJlS7S3tw96fLycD990HM5nxJ4PiTdFXJI333yzTJgwofzud78r//rXv8rKlSvLTTfdVD777LPsqV01zz77bNm2bVv59NNPy86dO8v3v//90tzcPOaPwdGjR8uePXvKnj17SkSU9evXlz179pR///vfpZRS1q1bV6rVann77bfL3r17yxNPPFFaWlpKo9FInvnQutBxOHr0aHn22WfLjh07yoEDB8rWrVvL3XffXb797W+PqePw4x//uFSr1bJt27Zy+PDhgXH8+PGBfcbD+fBNx2E0nQ+jJkKllPLrX/+6tLW1leuvv77cfvvtg25HHA8ee+yx0tLSUiZMmFBaW1vLo48+Wvbt25c9rWG3devWEhHnjKVLl5ZSztyWu3r16lKr1UqlUikLFy4se/fuzZ30MLjQcTh+/Hjp6OgoU6dOLRMmTCizZs0qS5cuLQcPHsye9pA63/cfEWXjxo0D+4yH8+GbjsNoOh/8KgcA0oyK14QAGJtECIA0IgRAGhECII0IAZBGhABII0IApBEhANKIEABpRAiANCIEQBoRAiDN/wPVMgWCwwrn4wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Part 1\n",
    "three = imageio.imread('mynum3.png')\n",
    "plt.imshow(three, cmap=plt.cm.gray)\n",
    "\n",
    "#Part 2\n",
    "new = np.zeros((1, 784))\n",
    "index = 0\n",
    "for box in three:\n",
    "    for pixel in box:\n",
    "        if pixel.mean() < 127:\n",
    "            new[0, index] = 0.0\n",
    "        else:\n",
    "            new[0, index] = 1.0\n",
    "        index += 1\n",
    "print(mlpbest.predict(new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
